{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练数据batch的大小\n",
    "BATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络的参数\n",
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在shape的一个维度上使用None可以方便使用不大的batch大小。在训练时需要把数据分成比较小的batch，但是在测试时，可以一次性使用全部的数据。当数据集比较abs小时，这样比较方便测试，但是数据集比较大时，将大量数据放入一个batch可能会导致内存溢出\n",
    "x=tf.placeholder(tf.float32,shape=(None,2),name='x-input')\n",
    "y_=tf.placeholder(tf.float32,shape=(None,1),name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络前向传播过程\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "\n",
    "# 在上面的代码中，y_代表正确结果，y代表预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和反向传播函数\n",
    "# 定义损失函数来刻画预测值与真实值之间的差距\n",
    "cross_entropy=-tf.reduce_mean(y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义学习率\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义反向传播算法来优化神经网络中的参数\n",
    "train_step=tf.train.AdadeltaOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过随机数生成一个模拟数据集\n",
    "rdm=RandomState(1)\n",
    "dataset_size=128\n",
    "X=rdm.rand(dataset_size,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义规则来给出样本的标签。这里所有x1+x2<1的样本都被认为是正样本，其他为负样本。这里使用0和1的表示方法\n",
    "Y=[[int(x1+x2)<1] for (x1,x2) in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 [[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "w2 [[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "------------------------------------------------------------------------------------------\n",
      "After 0 training step(s),cross entropy on all data is 0.0677411\n",
      "After 1000 training step(s),cross entropy on all data is 0.0676783\n",
      "After 2000 training step(s),cross entropy on all data is 0.0676121\n",
      "After 3000 training step(s),cross entropy on all data is 0.067546\n",
      "After 4000 training step(s),cross entropy on all data is 0.0674799\n",
      "------------------------------------------------------------------------------------------\n",
      "w1 [[-0.81270415  1.485931    0.06668379]\n",
      " [-2.443958    0.10045876  0.5924246 ]]\n",
      "w2 [[-0.8126457 ]\n",
      " [ 1.4860655 ]\n",
      " [ 0.06659038]]\n"
     ]
    }
   ],
   "source": [
    "# 创建一个会话来运行tensorflow程序\n",
    "with tf.Session() as sess:\n",
    "    init_op=tf.global_variables_initializer()\n",
    "    # 初始化变量\n",
    "    sess.run(init_op)\n",
    "    print('w1',sess.run(w1))\n",
    "    print('w2',sess.run(w2))\n",
    "    print('-'*90)\n",
    "    # 设定训练轮数\n",
    "    STEPS=5000\n",
    "    for i in range(STEPS):\n",
    "        # 每次选取batch_size个样本进行训练\n",
    "        start=(i*BATCH_SIZE)%dataset_size\n",
    "        end=min(start+BATCH_SIZE,dataset_size)\n",
    "        \n",
    "        # 通过选取的样本训练神经网络并更新参数\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        if i%1000==0:\n",
    "            # 每个一段时间计算在所有数据上的交叉熵并输出\n",
    "            total_cross_entropy=sess.run(cross_entropy,feed_dict={x:X,y_:Y})\n",
    "            print('After %d training step(s),cross entropy on all data is %g'%(i,total_cross_entropy))\n",
    "    print('-'*90)\n",
    "    print('w1',sess.run(w1))\n",
    "    print('w2',sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
